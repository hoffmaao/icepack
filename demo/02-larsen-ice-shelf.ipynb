{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import geojson\n",
    "import firedrake\n",
    "import icepack, icepack.plot, icepack.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larsen Ice Shelf\n",
    "\n",
    "This demo will involve using real data for the Larsen Ice Shelf in the Antarctic Peninsula.\n",
    "The use of real data will mostly change how we set up the simulation.\n",
    "The simulation itself -- involving successive prognostic and diagnostic solves of the physics model -- is virtually identical to what we saw in the last demo.\n",
    "\n",
    "To access the data, you'll need to have a login for [EarthData](https://urs.earthdata.nasa.gov/), the web portal through which NASA makes remote sensing data available to the public.\n",
    "Most of the ice sheet remote sensing data produced by American research institutions is hosted at the [National Snow and Ice Data Center (NSIDC)](https://www.nsidc.org) and an EarthData login is necessary to access data from NSIDC.\n",
    "\n",
    "The external data that we will use are:\n",
    "\n",
    "* an ice thickness map from the [bedmap2](https://www.bas.ac.uk/project/bedmap-2/) data set, which is available from the British Antarctic Survey\n",
    "* a velocity map of Antarctica produced as part of the MEaSUREs program, which you can read more about [here](https://nsidc.org/data/nsidc-0484)\n",
    "* a satellite image of all of Antarctica taken from [MODIS](https://en.wikipedia.org/wiki/Moderate_Resolution_Imaging_Spectroradiometer)\n",
    "* an outline of the Larsen C Ice Shelf, which I created by tracing over this satellite image in a [geographic information system](https://en.wikipedia.org/wiki/Geographic_information_system).\n",
    "\n",
    "Rather than manually download these data sets from the websites they're hosted on, we'll call a few functions in the module `data.py` in this directory to fetch them for us.\n",
    "(Internally, these functions use a library called [pooch](https://github.com/fatiando/pooch) which handles things like caching the data so it doesn't get downloaded twice, unzipping archived files, and so forth.)\n",
    "One we have these data sets we'll use the library [rasterio](https://rasterio.readthedocs.io/en/stable/) to read the gridded data and [GeoJSON](https://github.com/jazzband/python-geojson) for the vector data.\n",
    "Pooch, rasterio, and GeoJSON will have been installed along with icepack, so you don't need to do this yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometry\n",
    "\n",
    "First, we'll fetch a [GeoJSON](https://en.wikipedia.org/wiki/GeoJSON) file describing the outline of the domain.\n",
    "GeoJSON is a common file format for geospatial vector data.\n",
    "In the previous demo, we generated a .geo file describing the outline of the domain, and then called gmsh to create a triangulation of the interior.\n",
    "For this demo, we'll use a different helper script that will turn our .geojson file into the .geo format that gmsh expects.\n",
    "\n",
    "To retrieve the external data, we'll use several functions in the module `data.py`.\n",
    "All of these functions start with `fetch`.\n",
    "These functions retrieve the external data from the internet and put them in a predictable location so they can be found easily later.\n",
    "The files will only be downloaded the first time you fetch them.\n",
    "This caching functionality will come in handy because we'll be using much of the same data in later demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "outline_filename = data.fetch_larsen_outline()\n",
    "print(outline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read this file we'll use the GeoJSON package.\n",
    "We won't go into a great amount of detail about analyzing geospatial vector data here, but a few basic features are worth going over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outline_filename, 'r') as outline_file:\n",
    "    outline = geojson.load(outline_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the user's perspective, a GeoJSON object looks like a big nested dictionary, and somewhere down the line are some arrays of coordinates.\n",
    "Here we'll access the [coordinate reference system (CRS)](https://en.wikipedia.org/wiki/Spatial_reference_system) that the data are stored in.\n",
    "The most common reference systems are standardized and given numeric ID codes by a standards body, the European Petroleum Survey Group (EPSG).\n",
    "The most common CRS for Antarctic data sets is EPSG:3031, a stereographic projection centered on the South Pole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outline['crs']['properties']['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we care about in this GeoJSON object are the coordinates of all the features.\n",
    "Here we'll compute a bounding box for the domain to illustrate how one iterates over all of the features.\n",
    "In this case, every feature of this object is a `MultiLineString`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [feature['geometry'] for feature in outline['features']]\n",
    "xmin, ymin, xmax, ymax = np.inf, np.inf, -np.inf, -np.inf\n",
    "δ = 50e3\n",
    "for feature in outline['features']:\n",
    "    for line_string in feature['geometry']['coordinates']:\n",
    "        xs = np.array(line_string)\n",
    "        x, y = xs[:, 0], xs[:, 1]\n",
    "        xmin, ymin = min(xmin, x.min() - δ), min(ymin, y.min() - δ)\n",
    "        xmax, ymax = max(xmax, x.max() + δ), max(ymax, y.max() + δ)\n",
    "        \n",
    "print('{:e}, {:e}, {:e}, {:e}'.format(xmin, ymin, xmax, ymax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the domain outline below to see that everything lines up right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = icepack.plot.subplots()\n",
    "\n",
    "for feature in outline['features']:\n",
    "    for line_string in feature['geometry']['coordinates']:\n",
    "        xs = np.array(line_string)\n",
    "        axes.plot(xs[:, 0], xs[:, 1], linewidth=2)\n",
    "\n",
    "axes.set_xlabel('meters')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But without some additional context you might not know what each segment of the boundary corresponds to on the real ice shelf.\n",
    "To make that context more apparent, we'll show how to plot things on top of satellite imagery next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagery\n",
    "\n",
    "We'll use the [Mosaic of Antarctica (MOA)](https://nsidc.org/data/moa) as a background for all the plots we make in the following.\n",
    "This mosaic was created by compiling several hundred images from [MODIS](https://en.wikipedia.org/wiki/Moderate_Resolution_Imaging_Spectroradiometer).\n",
    "We could also use imagery from other satellites like Landsat-8 if we wanted higher spatial or radiometric resolution.\n",
    "\n",
    "The image mosaic is stored as a [GeoTIFF](https://en.wikipedia.org/wiki/GeoTIFF) file.\n",
    "GeoTIFF is a common storage format for geospatial data; it adds georeferencing information on top of the TIFF file format, which is often used for lossless compression of images.\n",
    "The function `rasterio.open` will give us an object representing the raster data set that we can then read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = data.fetch_mosaic_of_antarctica()\n",
    "image_file = rasterio.open(image_filename, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've opened the file but we haven't read any data yet.\n",
    "The image file covers all of Antarctica, so it would be wasteful to read the entire image.\n",
    "Instead, we'll read a window that covers the bounding box we calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = image_file.height, image_file.width\n",
    "transform = image_file.transform\n",
    "window = rasterio.windows.from_bounds(left=xmin, bottom=ymin, right=xmax, top=ymax,\n",
    "                                      width=width, height=height, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass the window to the `read` method of `image_file`, which will return a numpy array of the image values over the area that we want.\n",
    "The `indexes` argument specifies that we're reading only band 1; since this is a grayscale image, that's all we can read.\n",
    "For RGB or other multi-spectral images, you might want to get more of the spectral bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_file.read(indexes=1, window=window, masked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a figure showing the image of the Larsen Ice Shelf together with the various segments of the domain boundary.\n",
    "To add in the spatial coordinates of all the image pixels, we've passed in the bounding box of the window that we created earlier to `imshow` via the keyword `extent`.\n",
    "The `vmin` and `vmax` arguments were tuned by trial and error to get a nice contrast level.\n",
    "You can make out where the ice is grounded or floating, where there are ice rises, and if you change the balance quite a bit you can even pick out rifts in the ice shelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplots(*args, **kwargs):\n",
    "    fig, axes = icepack.plot.subplots()\n",
    "    xmin, ymin, xmax, ymax = rasterio.windows.bounds(window, transform)\n",
    "    axes.imshow(image, extent=(xmin, xmax, ymin, ymax),\n",
    "                cmap='Greys_r', vmin=12e3, vmax=16.38e3)\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this satellite image on every plot in this demo.\n",
    "Rather than add the same boilerplate code every time, the code above defines a wrapper function that creates figure and axes objects and adds the image to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "\n",
    "for feature in outline['features']:\n",
    "    for line_string in feature['geometry']['coordinates']:\n",
    "        xs = np.array(line_string)\n",
    "        axes.plot(xs[:, 0], xs[:, 1], linewidth=2)\n",
    "\n",
    "axes.set_xlabel('meters')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the domain boundary lines up well with features that are visible in the satellite image is a good sanity check.\n",
    "This way we know that the coordinate systems haven't been mixed up, that you haven't accidentally loaded up a mesh of a totally different ice shelf, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meshing\n",
    "\n",
    "Next we'll take this GeoJSON object and translate it into a geometry object from pygmsh.\n",
    "The function to do that is contained in the module `meshing.py`.\n",
    "We can then save this to a .geo file and run gmsh on the result, just like we did in the previous demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshing\n",
    "geometry = meshing.collection_to_geo(outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('larsen.geo', 'w') as geo_file:\n",
    "    geo_file.write(geometry.get_code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to gmsh is the same as in the previous demo, but we'll make the output less verbose by passing the flag `-v 2` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gmsh -2 -format msh2 -v 2 -o larsen.msh larsen.geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've generated the mesh we can read it just like we did in the previous demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = firedrake.Mesh('larsen.msh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll make a plot of the mesh so that we can see all the boundary IDs.\n",
    "Boundary segments 1 and 3 correspond to the calving terminus and these are where Neumann boundary conditions should be applied.\n",
    "Segment 2 borders the Gipps Ice Rise, and the remaining segments are where ice is flowing in from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "axes.set_xlabel('meters')\n",
    "icepack.plot.triplot(mesh, axes=axes, linewidth=1, bnd_linewidth=2)\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data\n",
    "\n",
    "Next, we have to load the input data, starting with the ice thickness.\n",
    "The bedmap2 dataset that we use actually includes several fields -- thickness, surface elevation, bed elevation, an ice shelf and rock mask, etc.\n",
    "The function `fetch_bedmap2` will download the dataset from the internet, unzip it, and return a list of the paths of all the files it retrieved rather than just a single file like the `fetch_larsen_mesh` function did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedmap2_files = data.fetch_bedmap2()\n",
    "for filename in bedmap2_files:\n",
    "    print(os.path.basename(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're only interested in the thickness data itself, so the following command will pull it out from the list of all the other files in the bedmap2 dataset.\n",
    "We can then read the thickness data just like we did for the image mosaic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness_filename = [f for f in bedmap2_files if\n",
    "                      os.path.basename(f) == 'bedmap2_thickness.tif'][0]\n",
    "\n",
    "thickness = rasterio.open(thickness_filename, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to fetch the velocity data, which are hosted on NSIDC.\n",
    "The following will prompt for your EarthData login if need be.\n",
    "The file is ~6GiB, so if you run this demo yourself, this step could take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_filename = data.fetch_measures_antarctica()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The velocity data are stored in a [NetCDF](https://en.wikipedia.org/wiki/NetCDF) file.\n",
    "NetCDF is another common storage format for geophysical data, especially in atmospheric science.\n",
    "NetCDF offers much more freedom than GeoTIFF in terms of what kind of data can be stored, so you have to know something about the schema or layout before you use it.\n",
    "For example, many fields can be stored by name in a NetCDF file, and you have to know what all the names are.\n",
    "The script `ncinfo` will print out information about all the fields stored in a NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncinfo \"$velocity_filename\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fields we want are `VX` and `VY`.\n",
    "We can use rasterio can read NetCDF files too, but we have to add in a bit of extra magic so it'll know that we want to get the `VX` and `VY`.\n",
    "To specify which field we're reading, we can prepend `netcdf:` to the beginning of the filename and append `:FIELD_NAME` to the string we pass to `rasterio.open`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = rasterio.open('netcdf:' + velocity_filename + ':VX', 'r')\n",
    "vy = rasterio.open('netcdf:' + velocity_filename + ':VY', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Having done all the leg work to make a mesh and get a good set of input data, the modeling itself should be fairly familiar from the last step.\n",
    "We'll assume that the ice temperature is a uniform $-13^\\circ$C.\n",
    "\n",
    "One thing is substantially different from previous examples.\n",
    "Before, we called the function `firedrake.SpatialCoordinate` to get some symbolic handles `x, y` for the mesh coordinates, and we created symbolic expressions to define the input data to our problem analytically.\n",
    "When we work with real data, we instead use icepack's `GridData` object, which firedrake doesn't know how to interpolate.\n",
    "The function `icepack.interpolate` works as a layer on top of the firedrake interpolate function and knows what to do with gridded data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2\n",
    "Q = firedrake.FunctionSpace(mesh, family='CG', degree=degree)\n",
    "V = firedrake.VectorFunctionSpace(mesh, family='CG', degree=degree)\n",
    "\n",
    "h0 = icepack.interpolate(thickness, Q)\n",
    "u0 = icepack.interpolate((vx, vy), V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "streamlines = icepack.plot.streamplot(u0, precision=1000, density=2500, axes=axes)\n",
    "fig.colorbar(streamlines, label='meters/year')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 260\n",
    "A = firedrake.interpolate(firedrake.Constant(icepack.rate_factor(T)), Q)\n",
    "\n",
    "ice_shelf = icepack.models.IceShelf()\n",
    "opts = {'dirichlet_ids': [2, 4, 5, 6, 7, 8, 9], 'tol': 1e-6}\n",
    "u = ice_shelf.diagnostic_solve(u0=u0, h=h0, A=A, **opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "streamlines = icepack.plot.streamplot(u, precision=1000, density=2500, axes=axes)\n",
    "fig.colorbar(streamlines, label='meters/year')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a fairly reasonable approximation for the velocity even with a spatially homogeneous guess for the ice temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(icepack.norm(u - u0) / icepack.norm(u0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ballpark estimate, the surface and basal mass balance of Larsen C are +30 and -30 cm/yr respectively, so we can take the total to be 0.\n",
    "Let's simulate the evolution of the ice shelf for the next 10 years.\n",
    "The code for this loop should be familiar from the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = firedrake.Function(Q)\n",
    "h = h0.copy(deepcopy=True)\n",
    "\n",
    "dt = 0.5\n",
    "num_steps = int(10 / dt)\n",
    "for n in range(num_steps + 1):\n",
    "    h = ice_shelf.prognostic_solve(dt, h0=h, a=a, u=u, h_inflow=h0)\n",
    "    u = ice_shelf.diagnostic_solve(u0=u, h=h, A=A, **opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot below we're using the `alpha` keyword argument to the contouring function.\n",
    "This makes the thickness contours about half-way transparent so we can see the satellite image underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "contours = icepack.plot.tricontourf(h, 20, alpha=0.6, axes=axes)\n",
    "fig.colorbar(contours, label='meters')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the difference between the modeled thickness after 10 years and the initial thickness, we can see the propagation of the rifts downstream.\n",
    "This effect is best visualized with a diverging colormap that makes the 0-contour really obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "δh = firedrake.Function(Q)\n",
    "δh.assign(h - h0)\n",
    "\n",
    "fig, axes = subplots()\n",
    "contours = icepack.plot.tricontourf(δh, axes=axes, cmap='RdBu', alpha=0.25,\n",
    "                                    levels=np.linspace(-10, +10, 11), extend='both')\n",
    "fig.colorbar(contours, label='meters')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The oscillatory pattern makes it less than obvious whether the ice shelf gained or lost mass, so let's evaluate the integral of the thickness change to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import assemble, dx\n",
    "print(assemble(δh * dx) / assemble(1 * dx(mesh)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as the simulation ran for 10 years, this isn't a wildly unrealistic number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In the last demo, we showed how to simulate ice shelf flow using synthetic data.\n",
    "Here we showed how to load in a generated mesh and observational data, and we used this same functionality to simulate a real ice shelf.\n",
    "\n",
    "Many real data sets require some amount of preprocessing before they can be used for modeling.\n",
    "For example, many velocity data sets have missing pixels or patches due to noise in the optical or radar imagery, and these missing points have to be filled in somehow.\n",
    "The Bedmap2 thickness also contains processing artifacts that are visible as depressions running diagonally across the ice shelf.\n",
    "These artifacts could be removed by using a low-pass filter on the gridded data, although this might also wash out some real features like the many rifts in the ice.\n",
    "\n",
    "In order to run the simulation, we had to come up with a guess for the ice rheology.\n",
    "The simple choice we made is quite far from the real value and in a subsequent demo we'll show how to estimate it from observational data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedrake",
   "language": "python",
   "name": "firedrake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
